{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 699: Tarea calificada 2, INAR 23-24\n",
    "\n",
    "## Generación de texto seq2seq model\n",
    "## A partir de textos de parlamentarios españoles (anteriores a 2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nota importante\n",
    "\n",
    "Esta tarea en su versión 2023-24 surge del excelente trabajo de varios compañeros del curso 2022-23, que aunque yo proporcioné un dataset de textos a partir de las intervenciones de parlamentarios (los líderes de varios partidos en 2021-22, alguno de los cuales ya no está en la política española), hicieron un extraordinario \"escrapeo\" de la web del Congreso de los Diputados y enriquecieron de forma notable el dataset. Este es el que propongo para esta tarea.\n",
    "\n",
    "Debo decir que si hay un texto (o lenguaje natural) libre de derechos y especialmente actual, son las intervenciones (estrictamente **públicas**) de los representantes elegidos en elecciones, y que el Congreso debería facilitar, no ya para su uso en estas tareas, sino para cualquier estudioso del español, o de la política, o de la psicología de los políticos.\n",
    "\n",
    "Por supuesto, esto son opiniones estrictamete mías, en el momento concreto en que las escribo, y sencillamente quiero hacer homenaje a los que colaboraron tanto con este trabajo que espero encontréis interesante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿De qué trata esta tarea?\n",
    "\n",
    "Pues ni más ni menos que de generar texto en español a partir de texto de parlamentarios, basado en el tutorial que hemos seguido en clase:\n",
    "\n",
    "https://www.tensorflow.org/text/tutorials/text_generation?hl=es-419\n",
    "\n",
    "Para facilitar la tarea se propone un pre-proceso (basado en la tarea 2021-22), y la tarea se concreta en el modelo para generar texto y en las pruebas de la calidad del texto generado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calificación\n",
    "\n",
    "Está explicada en la entrada correspondiente de Blackboard. Básicamente, hay un mínimo que consiste en proponer tres modelos de red recurrente, uno para cada parlamentario, entrenarlos, y **evaluarlos** generando texto y comentando su calidad.\n",
    "\n",
    "Para llegar a la máxima nota, propongo poner a dialogar los tres modelos.\n",
    "\n",
    "Pero por supuesto, valoraré el trabajo de construcción del modelo. Para esta tarea no hay una \"medida\" como la accuracy en la tarea 1. Será relativamente subjetiva. Por eso parece aconsejable comenzar con modelos pequeños o con pocas etapas e ir refinando."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "srXC6pLGLwS6"
   },
   "source": [
    "## Setup\n",
    "\n",
    "Para facilitar la tarea propongo unas cuantas casillas para cargar en memoria los textos, tres .txt que están incluidos en un .zip.\n",
    "\n",
    "## Nota importante\n",
    "\n",
    "La codificación (juego de caracteres) es UTF-8 y creo que debe seguir siendo así. *NO* abráis los .txt con el Notepad de Windows, sino con el Notepad+++ que os permitiría cambiarlo o devolverlo a UTF-8 (o Unicode si queréis).\n",
    "\n",
    "A pesar que la salida por pantalla (en mi sistema, un Linux) de caracteres ñ y acentuados parece que está mal, luego la generación de texto (insisto, lo he comprobado en mi sistema) es correcta en español.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WGyKZj3bzf9p"
   },
   "source": [
    "### Import TensorFlow and other libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T11:14:08.261025Z",
     "iopub.status.busy": "2022-05-03T11:14:08.260828Z",
     "iopub.status.idle": "2022-05-03T11:14:10.284556Z",
     "shell.execute_reply": "2022-05-03T11:14:10.283846Z"
    },
    "id": "yG_n40gFzf9s"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-13 12:55:10.741909: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-13 12:55:10.741984: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-13 12:55:10.744464: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-13 12:55:10.759278: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-13 12:55:12.734532: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EHDoRoc5PKWz"
   },
   "source": [
    "## Lectura de ficheros de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T11:14:10.288588Z",
     "iopub.status.busy": "2022-05-03T11:14:10.288339Z",
     "iopub.status.idle": "2022-05-03T11:14:10.512538Z",
     "shell.execute_reply": "2022-05-03T11:14:10.511842Z"
    },
    "id": "pD_55cOxLkAb"
   },
   "outputs": [],
   "source": [
    "datos_abascal   = \"intervencionesAbascal.txt\"\n",
    "datos_sanchez   = \"intervencionesSanchez.txt\"\n",
    "datos_casado    = \"intervencionesCasado.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UHjdCjDuSvX_"
   },
   "source": [
    "### Leer los ficheros de datos\n",
    "\n",
    "Primero, abrimos el texto de Santiago Abascal, que es el más corto, y lo leemos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T11:14:10.515842Z",
     "iopub.status.busy": "2022-05-03T11:14:10.515602Z",
     "iopub.status.idle": "2022-05-03T11:14:10.521336Z",
     "shell.execute_reply": "2022-05-03T11:14:10.520758Z"
    },
    "id": "aavnuByVymwK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto de Santiago Abascal: 22573 carácteres\n"
     ]
    }
   ],
   "source": [
    "# Read, then decode for py2 compat.\n",
    "text = open(datos_abascal, 'rb').read().decode(encoding='utf-8')\n",
    "\n",
    "# length of text is the number of characters in it\n",
    "print(f'Texto de Santiago Abascal: {len(text)} carácteres')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T11:14:10.524482Z",
     "iopub.status.busy": "2022-05-03T11:14:10.523966Z",
     "iopub.status.idle": "2022-05-03T11:14:10.527481Z",
     "shell.execute_reply": "2022-05-03T11:14:10.526931Z"
    },
    "id": "Duhg9NrUymwO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Señor Sánchez, ¿cómo se atreve usted a hablarme de monólogos si siempre trae las respuestas escritas, si usted nunca contesta a mis preguntas? Conteste por lo menos hoy. ¿Qué va a hacer usted para impedir que VOX siga cruzando las líneas que dice ust\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the first 250 characters in text\n",
    "print(text[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T11:14:10.530172Z",
     "iopub.status.busy": "2022-05-03T11:14:10.529967Z",
     "iopub.status.idle": "2022-05-03T11:14:10.544918Z",
     "shell.execute_reply": "2022-05-03T11:14:10.544310Z"
    },
    "id": "IlCgQBRVymwR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81 unique characters\n"
     ]
    }
   ],
   "source": [
    "# The unique characters in the file\n",
    "vocab = sorted(set(text))\n",
    "print(f'{len(vocab)} unique characters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a ver cual de los tres textos tiene el mayor vocabulario, para usar el mismo en los tres modelos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22573 carácteres, 81 únicos en intervencionesAbascal.txt\n",
      "239623 carácteres, 104 únicos en intervencionesSanchez.txt\n",
      "105940 carácteres, 92 únicos en intervencionesCasado.txt\n",
      "108 únicos en los tres textos\n"
     ]
    }
   ],
   "source": [
    "vocab_mayor = vocab\n",
    "\n",
    "textos = []\n",
    "\n",
    "for texto in [datos_abascal, datos_sanchez, datos_casado]:\n",
    "    text = open(texto, 'rb').read().decode(encoding='utf-8')\n",
    "    vocab = sorted(set(text))\n",
    "    print(f'{len(text)} carácteres, {len(vocab)} únicos en {texto}')\n",
    "    \n",
    "    if len(vocab) > len(vocab_mayor):\n",
    "        vocab_mayor = vocab\n",
    "    \n",
    "    textos.append(text)\n",
    "        \n",
    "vocab = sorted(set(textos[0] + textos[1] + textos[2]))\n",
    "print(f'{len(vocab)} únicos en los tres textos')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rNnrKn_lL-IJ"
   },
   "source": [
    "## Procesar el texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LFjSVAlWzf-N"
   },
   "source": [
    "### Vamos a vectorizar el texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como las redes neuronales no entienden carácteres sino números, vamos a vectorizar el texto. Para ello, vamos a crear dos *\"tablas de traducción\"*, uno para pasar de carácter a número y otro para pasar de número a carácter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-03T11:14:10.547650Z",
     "iopub.status.busy": "2022-05-03T11:14:10.547458Z",
     "iopub.status.idle": "2022-05-03T11:14:12.216225Z",
     "shell.execute_reply": "2022-05-03T11:14:12.215486Z"
    },
    "id": "a86OoYtO01go"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'\\x07': 0\n",
      "'\\n': 1\n",
      "' ': 2\n",
      "'!': 3\n",
      "'%': 4\n",
      "'&': 5\n",
      "'(': 6\n",
      "')': 7\n",
      "',': 8\n",
      "'-': 9\n",
      "'.': 10\n",
      "'0': 11\n",
      "'1': 12\n",
      "'2': 13\n",
      "'3': 14\n",
      "'4': 15\n",
      "'5': 16\n",
      "'6': 17\n",
      "'7': 18\n",
      "'8': 19\n"
     ]
    }
   ],
   "source": [
    "# Creamos un diccionario para asignar cada caracter a un entero\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "\n",
    "# Luego hacemos una lista con los carácteres ordenados por su entero\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "# Vamos a ver que pinta tiene nuestro diccionario\n",
    "for char,_ in zip(char2idx, range(20)):\n",
    "    print(f'{repr(char)}: {char2idx[char]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora ya podemos vectorizar el texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Señor Sánchez' ---- carácteres mapeados a int ----> [42 56 93 66 69  2 42 90 65 54 59 56 77]\n"
     ]
    }
   ],
   "source": [
    "# Ahora podemos convertir todo el texto a enteros\n",
    "text_as_int = np.array([char2idx[c] for c in text])\n",
    "\n",
    "# Vamos a ver como queda el texto en enteros\n",
    "print(f'{repr(text[:13])} ---- carácteres mapeados a int ----> {text_as_int[:13]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bbmsf23Bymwe"
   },
   "source": [
    "### The prediction task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wssHQ1oGymwe"
   },
   "source": [
    "Given a character, or a sequence of characters, what is the most probable next character? This is the task you're training the model to perform. The input to the model will be a sequence of characters, and you train the model to predict the output—the following character at each time step.\n",
    "\n",
    "Since RNNs maintain an internal state that depends on the previously seen elements, given all the characters computed until this moment, what is the next character?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hgsVvVxnymwf"
   },
   "source": [
    "# Fases propuestas para la elaboración del modelo\n",
    "\n",
    "### 1. Crear los training examples y los targets\n",
    "\n",
    "Ahora vamos a divir nuestro texto en secuencia de carácteres. Cada secuencia tendrá `seq_length` carácteres de nuestro texto.\n",
    "Para cada secuencia de entrada, los targets correspondientes contienen la misma longitud de texto, excepto desplazada un carácter a la derecha.\n",
    "Por eso dividimos el texto en secuencias de `seq_length+1`. Por ejemplo, digamos que `seq_length` es 4 y nuestro texto es \"Hola\". La secuencia de entrada sería \"Hol\" y la secuencia de salida \"ola\".\n",
    "\n",
    "Para hacer esto, primero usamos la función `tf.data.Dataset.from_tensor_slices` para convertir el vector de texto en una secuencia de índices de caracteres.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Secuencias de 100 carácteres:\n",
      "'Señor Sánchez, sus recetas económicas son tan creíbles como sus promesas electorales, y encima propon'\n",
      "'en las mismas recetas fracasadas que nos llevaron a la peor crisis económica de nuestra historia: más'\n",
      "' despilfarro, más déficit y más impuestos. Pero el Partido Popular es un partido de Estado y también '\n",
      "'de Gobierno, aunque estemos temporalmente en la oposición. Por eso el lunes le ofrecí pactar los Pres'\n",
      "'upuestos Generales si rompe con los independentistas, una oferta, por cierto, a la que usted no ha co'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-13 12:55:15.524950: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-13 12:55:15.771591: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-13 12:55:15.771706: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-13 12:55:15.786174: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-13 12:55:15.786338: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-13 12:55:15.786415: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-13 12:55:16.206792: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-13 12:55:16.206962: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-13 12:55:16.206978: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-12-13 12:55:16.207073: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-13 12:55:16.207106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3600 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# Creamos un dataset de tensorflow con los enteros\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "# Ahora vamos a dividir el texto en secuencias de 100 carácteres\n",
    "SEQ_LENGTH = 100\n",
    "sequences = char_dataset.batch(SEQ_LENGTH + 1, drop_remainder=True)\n",
    "\n",
    "# Vamos a ver como son estas secuencias\n",
    "print(\"Secuencias de 100 carácteres:\")\n",
    "for item in sequences.take(5):\n",
    "    print(repr(''.join(idx2char[item.numpy()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJdfPmdqzf-R"
   },
   "source": [
    "### 2. Crear los training batches\n",
    "\n",
    "El conjunto de datos de entrenamiento contiene tanto los datos de entrada (desde la posición 0 a la 99) como los de salida (desde la posición 1 a la 100). Por lo que necesitamos mapear el input y el target para crear el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  'Señor Sánchez, sus recetas económicas son tan creíbles como sus promesas electorales, y encima propo'\n",
      "Target:  'eñor Sánchez, sus recetas económicas son tan creíbles como sus promesas electorales, y encima propon'\n"
     ]
    }
   ],
   "source": [
    "def split_input_target(sequence):\n",
    "    input_text = sequence[:-1]\n",
    "    target_text = sequence[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "# Ahora vamos a aplicar la función anterior a todas las secuencias\n",
    "dataset = sequences.map(split_input_target)\n",
    "\n",
    "# Vamos a ver como son las secuencias de entrada y salida\n",
    "for input_example, target_example in  dataset.take(1):\n",
    "    print ('Input: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "    print ('Target: ', repr(''.join(idx2char[target_example.numpy()])))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora ya podemos mezclar los datos y empaquetarlos en batches de 64 secuencias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = (\n",
    "    dataset\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    ")\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r6oUuElIMgVx"
   },
   "source": [
    "## 3. Crear el modelo\n",
    "\n",
    "Puedes usar cualquiera de los modelos (RNN, LSTM, GRU) que hemos visto en clase. Por supuesto, del tamaño del modelo (capas, neuronas en cada capa) así como de las épocas (más adelante) dependerá el tiempo de proceso en el .fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el modelo de Abascal vamos a usar una RNN que contenga solo una capa LSTM. En concreto, definiremos una red neuronal de solo 3 capas:\n",
    "\n",
    "- Capa de entrada: una capa de tipo Embedding, que convierte los índices de los caracteres en vectores embedding de tamaño embedding_dim. En las opciones de la capa especificaremos el tamaño de nuestro vocabulario `(vocab_size)` y el tamaño de los vectores embedding `(embedding_dim)`. También indicaremos el tamaño del batch que vamos a usar `(batch_size)`.\n",
    "\n",
    "- Capa LSTM: una capa LSTM con `units=2048`, que es el número de neuronas recurrentes de la capa. También indicaremos con return_sequences=True que queremos predecir el carácter siguiente a todos los carácteres de entrada y no solo al último carácter. El argumento `stateful=True` explica el uso de las capacidades de memoria de la red entre batches: Si está en False, por cada nuevo batch se inicializan las memory cells (la parte de la red neuronal que preserva el estado de la red a través del tiempo), pero si está en True, por cada nuevo batch se mantienen las memory cells con las actualizaciones hechas durante la ejecución del batch anterior. El último argumento, `recurrent_initializer='glorot_uniform'`, es un que indica como se inicializan los pesos de las matrices internas de la capa LSTM. En estos casosm la distribución más común es la `glorot_uniform`.\n",
    "\n",
    "- Capa de salida: una capa Dense con `vocab_size` neuronas. Esta capa nos dará como salida un vector de tamaño `vocab_size` con las probabilidades de que el siguiente carácter sea cada uno de los carácteres del vocabulario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (64, None, 512)           55296     \n",
      "                                                                 \n",
      " lstm (LSTM)                 (64, None, 2048)          20979712  \n",
      "                                                                 \n",
      " dense (Dense)               (64, None, 108)           221292    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21256300 (81.09 MB)\n",
      "Trainable params: 21256300 (81.09 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = Sequential([\n",
    "        Embedding(vocab_size, embedding_dim,\n",
    "                  batch_input_shape=[batch_size, None]),\n",
    "        LSTM(rnn_units, return_sequences=True,\n",
    "             recurrent_initializer='glorot_uniform',\n",
    "             stateful=True),\n",
    "        Dense(vocab_size)\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "embedding_dim = 512\n",
    "rnn_units = 2048\n",
    "\n",
    "model = build_model(\n",
    "    vocab_size=len(vocab),\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units,\n",
    "    batch_size=BATCH_SIZE)\n",
    "\n",
    "model.summary()\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos nuestra función de pérdida y el optimizador que vamos a usar para entrenar el modelo. En este caso, usaremos la función de pérdida `sparse_categorical_crossentropy` y el optimizador `Adam` con sus argumentos por defecto. Con esto ya podemos compilar el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos usar la técnica de los checkpoints para no perder el progreso del entrenamiento si tenemos un fallo en el sistema. El único problema es que los checkpoints pueden llegar a ocupar mucho espacio muy rápidamente, por lo que es recomendable borrarlos después de entrenarlos y en su lugar guardar el modelo ya terminado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m8gPwEjRzf-Z"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ubPo0_9Prjb"
   },
   "source": [
    "## 4. Summary y fit del modelo\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-13 12:55:20.045617: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n",
      "Could not load symbol cublasGetSmCountTarget from libcublas.so.11. Error: /home/antonio/.anaconda3/envs/tf/lib/./libcublas.so.11: undefined symbol: cublasGetSmCountTarget\n",
      "2023-12-13 12:55:20.167953: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f2a742b01c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-12-13 12:55:20.168047: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
      "2023-12-13 12:55:20.178246: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1702468520.310589   83645 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 8s 258ms/step - loss: 3.9156\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 4s 257ms/step - loss: 2.9504\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 4s 255ms/step - loss: 2.7219\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 4s 219ms/step - loss: 2.4696\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 4s 261ms/step - loss: 2.3360\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 4s 262ms/step - loss: 2.2489\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 6s 353ms/step - loss: 2.1799\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 5s 327ms/step - loss: 2.1150\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 4s 259ms/step - loss: 2.0454\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 4s 256ms/step - loss: 1.9866\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 4s 266ms/step - loss: 1.9259\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 5s 281ms/step - loss: 1.8569\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 4s 264ms/step - loss: 1.8010\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 4s 252ms/step - loss: 1.7497\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 4s 263ms/step - loss: 1.6995\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 4s 264ms/step - loss: 1.6401\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 4s 269ms/step - loss: 1.5820\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 4s 253ms/step - loss: 1.5250\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 5s 312ms/step - loss: 1.4740\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 4s 277ms/step - loss: 1.4263\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 3s 188ms/step - loss: 1.3701\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 4s 280ms/step - loss: 1.3150\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 5s 280ms/step - loss: 1.2640\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 4s 243ms/step - loss: 1.2039\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 4s 266ms/step - loss: 1.1543\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 4s 238ms/step - loss: 1.0909\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 4s 273ms/step - loss: 1.0373\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 4s 232ms/step - loss: 0.9744\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 4s 253ms/step - loss: 0.9112\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 4s 263ms/step - loss: 0.8429\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 4s 250ms/step - loss: 0.7719\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 4s 275ms/step - loss: 0.7057\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 4s 275ms/step - loss: 0.6468\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 4s 277ms/step - loss: 0.5825\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 4s 270ms/step - loss: 0.5187\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 4s 256ms/step - loss: 0.4630\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 4s 276ms/step - loss: 0.4147\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 4s 264ms/step - loss: 0.3772\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 4s 262ms/step - loss: 0.3485\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 4s 253ms/step - loss: 0.3195\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 3s 175ms/step - loss: 0.3006\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 3s 163ms/step - loss: 0.2775\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 2s 152ms/step - loss: 0.2626\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 4s 248ms/step - loss: 0.2486\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 4s 276ms/step - loss: 0.2388\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 5s 282ms/step - loss: 0.2327\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 4s 255ms/step - loss: 0.2210\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 4s 263ms/step - loss: 0.2149\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 4s 270ms/step - loss: 0.2074\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 4s 273ms/step - loss: 0.2024\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 4s 269ms/step - loss: 0.1974\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 4s 257ms/step - loss: 0.1943\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 4s 258ms/step - loss: 0.1904\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 4s 266ms/step - loss: 0.1844\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 4s 264ms/step - loss: 0.1796\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 4s 273ms/step - loss: 0.1774\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 4s 270ms/step - loss: 0.1743\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 4s 272ms/step - loss: 0.1723\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 4s 267ms/step - loss: 0.1706\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 4s 252ms/step - loss: 0.1665\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 4s 266ms/step - loss: 0.1639\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 5s 287ms/step - loss: 0.1605\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 4s 263ms/step - loss: 0.1562\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 4s 250ms/step - loss: 0.1576\n",
      "Epoch 65/200\n",
      "16/16 [==============================] - 4s 261ms/step - loss: 0.1526\n",
      "Epoch 66/200\n",
      "16/16 [==============================] - 4s 262ms/step - loss: 0.1526\n",
      "Epoch 67/200\n",
      "16/16 [==============================] - 4s 255ms/step - loss: 0.1501\n",
      "Epoch 68/200\n",
      "16/16 [==============================] - 4s 252ms/step - loss: 0.1463\n",
      "Epoch 69/200\n",
      "16/16 [==============================] - 4s 262ms/step - loss: 0.1450\n",
      "Epoch 70/200\n",
      "16/16 [==============================] - 4s 264ms/step - loss: 0.1437\n",
      "Epoch 71/200\n",
      "16/16 [==============================] - 4s 273ms/step - loss: 0.1428\n",
      "Epoch 72/200\n",
      "16/16 [==============================] - 4s 250ms/step - loss: 0.1413\n",
      "Epoch 73/200\n",
      "16/16 [==============================] - 4s 266ms/step - loss: 0.1406\n",
      "Epoch 74/200\n",
      "16/16 [==============================] - 4s 277ms/step - loss: 0.1395\n",
      "Epoch 75/200\n",
      "16/16 [==============================] - 4s 271ms/step - loss: 0.1379\n",
      "Epoch 76/200\n",
      "16/16 [==============================] - 4s 266ms/step - loss: 0.1357\n",
      "Epoch 77/200\n",
      "16/16 [==============================] - 4s 265ms/step - loss: 0.1346\n",
      "Epoch 78/200\n",
      "16/16 [==============================] - 4s 272ms/step - loss: 0.1322\n",
      "Epoch 79/200\n",
      "16/16 [==============================] - 4s 273ms/step - loss: 0.1318\n",
      "Epoch 80/200\n",
      "16/16 [==============================] - 5s 281ms/step - loss: 0.1280\n",
      "Epoch 81/200\n",
      "16/16 [==============================] - 4s 271ms/step - loss: 0.1284\n",
      "Epoch 82/200\n",
      "16/16 [==============================] - 4s 274ms/step - loss: 0.1269\n",
      "Epoch 83/200\n",
      "16/16 [==============================] - 5s 284ms/step - loss: 0.1261\n",
      "Epoch 84/200\n",
      "16/16 [==============================] - 4s 259ms/step - loss: 0.1243\n",
      "Epoch 85/200\n",
      "16/16 [==============================] - 4s 265ms/step - loss: 0.1269\n",
      "Epoch 86/200\n",
      "16/16 [==============================] - 4s 256ms/step - loss: 0.1237\n",
      "Epoch 87/200\n",
      "16/16 [==============================] - 4s 264ms/step - loss: 0.1217\n",
      "Epoch 88/200\n",
      "16/16 [==============================] - 4s 271ms/step - loss: 0.1219\n",
      "Epoch 89/200\n",
      "16/16 [==============================] - 4s 260ms/step - loss: 0.1201\n",
      "Epoch 90/200\n",
      "16/16 [==============================] - 4s 266ms/step - loss: 0.1191\n",
      "Epoch 91/200\n",
      "16/16 [==============================] - 4s 268ms/step - loss: 0.1184\n",
      "Epoch 92/200\n",
      "16/16 [==============================] - 4s 263ms/step - loss: 0.1170\n",
      "Epoch 93/200\n",
      "16/16 [==============================] - 4s 257ms/step - loss: 0.1177\n",
      "Epoch 94/200\n",
      "16/16 [==============================] - 4s 262ms/step - loss: 0.1158\n",
      "Epoch 95/200\n",
      "16/16 [==============================] - 3s 186ms/step - loss: 0.1148\n",
      "Epoch 96/200\n",
      "16/16 [==============================] - 4s 253ms/step - loss: 0.1124\n",
      "Epoch 97/200\n",
      "16/16 [==============================] - 5s 283ms/step - loss: 0.1139\n",
      "Epoch 98/200\n",
      "16/16 [==============================] - 4s 273ms/step - loss: 0.1128\n",
      "Epoch 99/200\n",
      "16/16 [==============================] - 5s 295ms/step - loss: 0.1127\n",
      "Epoch 100/200\n",
      "16/16 [==============================] - 5s 299ms/step - loss: 0.1101\n",
      "Epoch 101/200\n",
      "16/16 [==============================] - 5s 302ms/step - loss: 0.1130\n",
      "Epoch 102/200\n",
      "16/16 [==============================] - 5s 293ms/step - loss: 0.1116\n",
      "Epoch 103/200\n",
      "16/16 [==============================] - 5s 296ms/step - loss: 0.1115\n",
      "Epoch 104/200\n",
      "16/16 [==============================] - 5s 321ms/step - loss: 0.1115\n",
      "Epoch 105/200\n",
      "16/16 [==============================] - 5s 284ms/step - loss: 0.1116\n",
      "Epoch 106/200\n",
      "16/16 [==============================] - 5s 285ms/step - loss: 0.1052\n",
      "Epoch 107/200\n",
      "16/16 [==============================] - 5s 289ms/step - loss: 0.1085\n",
      "Epoch 108/200\n",
      "16/16 [==============================] - 5s 293ms/step - loss: 0.1065\n",
      "Epoch 109/200\n",
      "16/16 [==============================] - 5s 285ms/step - loss: 0.1058\n",
      "Epoch 110/200\n",
      "16/16 [==============================] - 5s 292ms/step - loss: 0.1053\n",
      "Epoch 111/200\n",
      "16/16 [==============================] - 5s 294ms/step - loss: 0.1026\n",
      "Epoch 112/200\n",
      "16/16 [==============================] - 5s 292ms/step - loss: 0.1031\n",
      "Epoch 113/200\n",
      "16/16 [==============================] - 5s 297ms/step - loss: 0.1013\n",
      "Epoch 114/200\n",
      "16/16 [==============================] - 5s 290ms/step - loss: 0.1037\n",
      "Epoch 115/200\n",
      "16/16 [==============================] - 4s 276ms/step - loss: 0.1038\n",
      "Epoch 116/200\n",
      "16/16 [==============================] - 5s 288ms/step - loss: 0.1024\n",
      "Epoch 117/200\n",
      "16/16 [==============================] - 4s 247ms/step - loss: 0.1012\n",
      "Epoch 118/200\n",
      "16/16 [==============================] - 3s 158ms/step - loss: 0.1019\n",
      "Epoch 119/200\n",
      "16/16 [==============================] - 3s 200ms/step - loss: 0.1012\n",
      "Epoch 120/200\n",
      "16/16 [==============================] - 5s 292ms/step - loss: 0.1015\n",
      "Epoch 121/200\n",
      "16/16 [==============================] - 5s 301ms/step - loss: 0.1015\n",
      "Epoch 122/200\n",
      "16/16 [==============================] - 5s 293ms/step - loss: 0.1010\n",
      "Epoch 123/200\n",
      "16/16 [==============================] - 5s 294ms/step - loss: 0.0992\n",
      "Epoch 124/200\n",
      "16/16 [==============================] - 5s 296ms/step - loss: 0.0996\n",
      "Epoch 125/200\n",
      "16/16 [==============================] - 5s 293ms/step - loss: 0.0991\n",
      "Epoch 126/200\n",
      "16/16 [==============================] - 5s 283ms/step - loss: 0.0976\n",
      "Epoch 127/200\n",
      "16/16 [==============================] - 3s 205ms/step - loss: 0.0978\n",
      "Epoch 128/200\n",
      "16/16 [==============================] - 2s 147ms/step - loss: 0.0975\n",
      "Epoch 129/200\n",
      "16/16 [==============================] - 2s 149ms/step - loss: 0.0977\n",
      "Epoch 130/200\n",
      "16/16 [==============================] - 2s 149ms/step - loss: 0.0968\n",
      "Epoch 131/200\n",
      "16/16 [==============================] - 5s 294ms/step - loss: 0.0960\n",
      "Epoch 132/200\n",
      "16/16 [==============================] - 5s 290ms/step - loss: 0.0956\n",
      "Epoch 133/200\n",
      "16/16 [==============================] - 5s 285ms/step - loss: 0.0958\n",
      "Epoch 134/200\n",
      "16/16 [==============================] - 5s 296ms/step - loss: 0.0957\n",
      "Epoch 135/200\n",
      "16/16 [==============================] - 5s 290ms/step - loss: 0.0950\n",
      "Epoch 136/200\n",
      "16/16 [==============================] - 5s 292ms/step - loss: 0.0921\n",
      "Epoch 137/200\n",
      "16/16 [==============================] - 5s 292ms/step - loss: 0.0935\n",
      "Epoch 138/200\n",
      "16/16 [==============================] - 5s 284ms/step - loss: 0.0945\n",
      "Epoch 139/200\n",
      "16/16 [==============================] - 5s 305ms/step - loss: 0.0944\n",
      "Epoch 140/200\n",
      "16/16 [==============================] - 5s 297ms/step - loss: 0.0968\n",
      "Epoch 141/200\n",
      "16/16 [==============================] - 5s 305ms/step - loss: 0.0940\n",
      "Epoch 142/200\n",
      "16/16 [==============================] - 5s 298ms/step - loss: 0.0924\n",
      "Epoch 143/200\n",
      "16/16 [==============================] - 5s 304ms/step - loss: 0.0936\n",
      "Epoch 144/200\n",
      "16/16 [==============================] - 5s 317ms/step - loss: 0.0925\n",
      "Epoch 145/200\n",
      "16/16 [==============================] - 5s 300ms/step - loss: 0.0938\n",
      "Epoch 146/200\n",
      "16/16 [==============================] - 5s 288ms/step - loss: 0.0923\n",
      "Epoch 147/200\n",
      "16/16 [==============================] - 5s 300ms/step - loss: 0.0931\n",
      "Epoch 148/200\n",
      "16/16 [==============================] - 5s 302ms/step - loss: 0.0901\n",
      "Epoch 149/200\n",
      "16/16 [==============================] - 5s 310ms/step - loss: 0.0912\n",
      "Epoch 150/200\n",
      "16/16 [==============================] - 5s 316ms/step - loss: 0.0922\n",
      "Epoch 151/200\n",
      "16/16 [==============================] - 6s 349ms/step - loss: 0.0924\n",
      "Epoch 152/200\n",
      "16/16 [==============================] - 5s 285ms/step - loss: 0.0899\n",
      "Epoch 153/200\n",
      "16/16 [==============================] - 4s 269ms/step - loss: 0.0891\n",
      "Epoch 154/200\n",
      "16/16 [==============================] - 5s 292ms/step - loss: 0.0906\n",
      "Epoch 155/200\n",
      "16/16 [==============================] - 5s 296ms/step - loss: 0.0889\n",
      "Epoch 156/200\n",
      "16/16 [==============================] - 5s 301ms/step - loss: 0.0894\n",
      "Epoch 157/200\n",
      "16/16 [==============================] - 5s 302ms/step - loss: 0.0867\n",
      "Epoch 158/200\n",
      "16/16 [==============================] - 5s 296ms/step - loss: 0.0881\n",
      "Epoch 159/200\n",
      "16/16 [==============================] - 5s 292ms/step - loss: 0.0877\n",
      "Epoch 160/200\n",
      "16/16 [==============================] - 5s 297ms/step - loss: 0.0883\n",
      "Epoch 161/200\n",
      "16/16 [==============================] - 5s 297ms/step - loss: 0.0871\n",
      "Epoch 162/200\n",
      "16/16 [==============================] - 5s 302ms/step - loss: 0.0877\n",
      "Epoch 163/200\n",
      "16/16 [==============================] - 5s 299ms/step - loss: 0.0880\n",
      "Epoch 164/200\n",
      "16/16 [==============================] - 5s 312ms/step - loss: 0.0867\n",
      "Epoch 165/200\n",
      "16/16 [==============================] - 4s 267ms/step - loss: 0.0852\n",
      "Epoch 166/200\n",
      "16/16 [==============================] - 5s 283ms/step - loss: 0.0860\n",
      "Epoch 167/200\n",
      "16/16 [==============================] - 4s 272ms/step - loss: 0.0870\n",
      "Epoch 168/200\n",
      "16/16 [==============================] - 5s 279ms/step - loss: 0.0845\n",
      "Epoch 169/200\n",
      "16/16 [==============================] - 4s 268ms/step - loss: 0.0859\n",
      "Epoch 170/200\n",
      "16/16 [==============================] - 5s 279ms/step - loss: 0.0847\n",
      "Epoch 171/200\n",
      "16/16 [==============================] - 4s 261ms/step - loss: 0.0861\n",
      "Epoch 172/200\n",
      "16/16 [==============================] - 4s 243ms/step - loss: 0.0852\n",
      "Epoch 173/200\n",
      "16/16 [==============================] - 4s 218ms/step - loss: 0.0870\n",
      "Epoch 174/200\n",
      "16/16 [==============================] - 4s 236ms/step - loss: 0.0876\n",
      "Epoch 175/200\n",
      "16/16 [==============================] - 4s 247ms/step - loss: 0.0829\n",
      "Epoch 176/200\n",
      "16/16 [==============================] - 4s 238ms/step - loss: 0.0850\n",
      "Epoch 177/200\n",
      "16/16 [==============================] - 4s 253ms/step - loss: 0.0851\n",
      "Epoch 178/200\n",
      "16/16 [==============================] - 4s 276ms/step - loss: 0.0852\n",
      "Epoch 179/200\n",
      "16/16 [==============================] - 4s 269ms/step - loss: 0.0860\n",
      "Epoch 180/200\n",
      "16/16 [==============================] - 4s 234ms/step - loss: 0.0860\n",
      "Epoch 181/200\n",
      "16/16 [==============================] - 4s 237ms/step - loss: 0.0870\n",
      "Epoch 182/200\n",
      "16/16 [==============================] - 4s 251ms/step - loss: 0.0858\n",
      "Epoch 183/200\n",
      "16/16 [==============================] - 4s 245ms/step - loss: 0.0846\n",
      "Epoch 184/200\n",
      "16/16 [==============================] - 4s 226ms/step - loss: 0.0841\n",
      "Epoch 185/200\n",
      "16/16 [==============================] - 4s 221ms/step - loss: 0.0834\n",
      "Epoch 186/200\n",
      "16/16 [==============================] - 4s 245ms/step - loss: 0.0843\n",
      "Epoch 187/200\n",
      "16/16 [==============================] - 4s 245ms/step - loss: 0.0836\n",
      "Epoch 188/200\n",
      "16/16 [==============================] - 4s 251ms/step - loss: 0.0814\n",
      "Epoch 189/200\n",
      "16/16 [==============================] - 4s 248ms/step - loss: 0.0837\n",
      "Epoch 190/200\n",
      "16/16 [==============================] - 4s 251ms/step - loss: 0.0836\n",
      "Epoch 191/200\n",
      "16/16 [==============================] - 4s 251ms/step - loss: 0.0846\n",
      "Epoch 192/200\n",
      "16/16 [==============================] - 4s 246ms/step - loss: 0.0838\n",
      "Epoch 193/200\n",
      "16/16 [==============================] - 4s 230ms/step - loss: 0.0833\n",
      "Epoch 194/200\n",
      "16/16 [==============================] - 4s 235ms/step - loss: 0.0825\n",
      "Epoch 195/200\n",
      "16/16 [==============================] - 4s 233ms/step - loss: 0.0830\n",
      "Epoch 196/200\n",
      "16/16 [==============================] - 4s 271ms/step - loss: 0.0826\n",
      "Epoch 197/200\n",
      "16/16 [==============================] - 5s 278ms/step - loss: 0.0819\n",
      "Epoch 198/200\n",
      "16/16 [==============================] - 5s 286ms/step - loss: 0.0839\n",
      "Epoch 199/200\n",
      "16/16 [==============================] - 5s 282ms/step - loss: 0.0818\n",
      "Epoch 200/200\n",
      "16/16 [==============================] - 5s 290ms/step - loss: 0.0805\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 200\n",
    "\n",
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])\n",
    "\n",
    "# Guardamos el modelo y los pesos\n",
    "model.save_weights('./modelos/abascal_weights.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que hemos terminado de entranar el modelo ya no necesitamos los chekpoints, por lo que podemos borrarlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Borramos los checkpoints para no ocupar espacio\n",
    "\n",
    "import os, shutil\n",
    "folder = './training_checkpoints/'\n",
    "\n",
    "for filename in os.listdir(folder):\n",
    "    file_path = os.path.join(folder, filename)\n",
    "    try:\n",
    "        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "            os.unlink(file_path)\n",
    "        elif os.path.isdir(file_path):\n",
    "            shutil.rmtree(file_path)\n",
    "    except Exception as e:\n",
    "        print('Failed to delete %s. Reason: %s' % (file_path, e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kKkD5M6eoSiN"
   },
   "source": [
    "## 5. Genera texto y evalúa su calidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para generar texto a partir del modelo, ahora necesitamos un `batch_size` de 1, por lo que tenemos que rehacer el modelo y cargar los pesos de nuestro modelo entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "model.load_weights('./modelos/abascal_weights.keras')\n",
    "model.build(tf.TensorShape([1, None]))\n",
    "\n",
    "model.save('./modelos/abascal.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "    \n",
    "    num_generate = 500\n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    \n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "    text_generated = []\n",
    "    temperature = 0.5\n",
    "    \n",
    "    model.reset_states()\n",
    "    \n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        \n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "        \n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "        \n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "        \n",
    "    return (''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ¿No va a destruir a ministros, a barones, también a sus socios de Gobierno, al Consejo de Estado, y hasta a los jueces y las pensiones; que no trabaje para su fragmentación, sino para ser admirada en el mundo; que no se puede agredir así a las instituciones con la complicidad de este Gobierno. No todo vale, basta y que hay que apedrearle  solo porque sus padres hayan pedido que se cumplan los derechos en la cárcel le vuelve a hacer sentarse en una mesa por la autodeterminación. Y para su vergüe\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=u\"Señor Abascal, ¿que opina del precio de la luz?\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y4QwTjAM6A2O"
   },
   "source": [
    "## 6. Trabajo adicional\n",
    "\n",
    "Por ejemplo, poner en cadena los tres modelos para que \"dialoguen\" entre sí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de Pedro Sánchez"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el dataset de entrenamiento de Pedro Sánchez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abrir el texto\n",
    "text = open(datos_sanchez, 'rb').read().decode(encoding='utf-8')\n",
    "\n",
    "# Vectorizar el texto\n",
    "text_as_int = np.array([char2idx[c] for c in text])\n",
    "\n",
    "# Secuencias de 100 carácteres\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "SEQ_LENGTH = 100\n",
    "sequences = char_dataset.batch(SEQ_LENGTH + 1, drop_remainder=True)\n",
    "\n",
    "# Dataset de entrenamiento\n",
    "dataset = sequences.map(split_input_target)\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = (\n",
    "    dataset\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora creamos el modelo de Pedro Sánchez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "    vocab_size=len(vocab),\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units,\n",
    "    batch_size=BATCH_SIZE)\n",
    "\n",
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo de Pedro Sánchez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "37/37 [==============================] - 11s 261ms/step - loss: 3.3824\n",
      "Epoch 2/200\n",
      "37/37 [==============================] - 10s 267ms/step - loss: 2.5508\n",
      "Epoch 3/200\n",
      "37/37 [==============================] - 10s 269ms/step - loss: 2.2240\n",
      "Epoch 4/200\n",
      "37/37 [==============================] - 10s 267ms/step - loss: 2.0462\n",
      "Epoch 5/200\n",
      "37/37 [==============================] - 10s 264ms/step - loss: 1.8751\n",
      "Epoch 6/200\n",
      "37/37 [==============================] - 10s 259ms/step - loss: 1.7157\n",
      "Epoch 7/200\n",
      "37/37 [==============================] - 6s 166ms/step - loss: 1.5714\n",
      "Epoch 8/200\n",
      "37/37 [==============================] - 5s 133ms/step - loss: 1.4418\n",
      "Epoch 9/200\n",
      "37/37 [==============================] - 11s 284ms/step - loss: 1.3399\n",
      "Epoch 10/200\n",
      "37/37 [==============================] - 11s 279ms/step - loss: 1.2468\n",
      "Epoch 11/200\n",
      "37/37 [==============================] - 9s 243ms/step - loss: 1.1700\n",
      "Epoch 12/200\n",
      "37/37 [==============================] - 9s 248ms/step - loss: 1.1055\n",
      "Epoch 13/200\n",
      "37/37 [==============================] - 9s 251ms/step - loss: 1.0454\n",
      "Epoch 14/200\n",
      "37/37 [==============================] - 9s 249ms/step - loss: 0.9886\n",
      "Epoch 15/200\n",
      "37/37 [==============================] - 9s 247ms/step - loss: 0.9374\n",
      "Epoch 16/200\n",
      "37/37 [==============================] - 9s 242ms/step - loss: 0.8879\n",
      "Epoch 17/200\n",
      "37/37 [==============================] - 9s 249ms/step - loss: 0.8345\n",
      "Epoch 18/200\n",
      "37/37 [==============================] - 10s 260ms/step - loss: 0.7872\n",
      "Epoch 19/200\n",
      "37/37 [==============================] - 10s 258ms/step - loss: 0.7388\n",
      "Epoch 20/200\n",
      "37/37 [==============================] - 10s 259ms/step - loss: 0.6858\n",
      "Epoch 21/200\n",
      "37/37 [==============================] - 8s 218ms/step - loss: 0.6360\n",
      "Epoch 22/200\n",
      "37/37 [==============================] - 9s 244ms/step - loss: 0.5845\n",
      "Epoch 23/200\n",
      "37/37 [==============================] - 7s 183ms/step - loss: 0.5353\n",
      "Epoch 24/200\n",
      "37/37 [==============================] - 10s 264ms/step - loss: 0.4885\n",
      "Epoch 25/200\n",
      "37/37 [==============================] - 10s 272ms/step - loss: 0.4453\n",
      "Epoch 26/200\n",
      "37/37 [==============================] - 9s 223ms/step - loss: 0.4072\n",
      "Epoch 27/200\n",
      "37/37 [==============================] - 8s 200ms/step - loss: 0.3730\n",
      "Epoch 28/200\n",
      "37/37 [==============================] - 10s 276ms/step - loss: 0.3447\n",
      "Epoch 29/200\n",
      "37/37 [==============================] - 10s 273ms/step - loss: 0.3196\n",
      "Epoch 30/200\n",
      "37/37 [==============================] - 9s 230ms/step - loss: 0.2988\n",
      "Epoch 31/200\n",
      "37/37 [==============================] - 9s 248ms/step - loss: 0.2809\n",
      "Epoch 32/200\n",
      "37/37 [==============================] - 10s 253ms/step - loss: 0.2683\n",
      "Epoch 33/200\n",
      "37/37 [==============================] - 9s 230ms/step - loss: 0.2524\n",
      "Epoch 34/200\n",
      "37/37 [==============================] - 8s 212ms/step - loss: 0.2395\n",
      "Epoch 35/200\n",
      "37/37 [==============================] - 10s 259ms/step - loss: 0.2325\n",
      "Epoch 36/200\n",
      "37/37 [==============================] - 10s 270ms/step - loss: 0.2255\n",
      "Epoch 37/200\n",
      "37/37 [==============================] - 10s 278ms/step - loss: 0.2179\n",
      "Epoch 38/200\n",
      "37/37 [==============================] - 10s 277ms/step - loss: 0.2123\n",
      "Epoch 39/200\n",
      "37/37 [==============================] - 10s 253ms/step - loss: 0.2063\n",
      "Epoch 40/200\n",
      "37/37 [==============================] - 9s 242ms/step - loss: 0.2012\n",
      "Epoch 41/200\n",
      "37/37 [==============================] - 10s 253ms/step - loss: 0.1957\n",
      "Epoch 42/200\n",
      "37/37 [==============================] - 9s 250ms/step - loss: 0.1908\n",
      "Epoch 43/200\n",
      "37/37 [==============================] - 10s 250ms/step - loss: 0.1884\n",
      "Epoch 44/200\n",
      "37/37 [==============================] - 9s 244ms/step - loss: 0.1850\n",
      "Epoch 45/200\n",
      "37/37 [==============================] - 9s 240ms/step - loss: 0.1803\n",
      "Epoch 46/200\n",
      "37/37 [==============================] - 9s 234ms/step - loss: 0.1774\n",
      "Epoch 47/200\n",
      "37/37 [==============================] - 8s 222ms/step - loss: 0.1756\n",
      "Epoch 48/200\n",
      "37/37 [==============================] - 9s 244ms/step - loss: 0.1719\n",
      "Epoch 49/200\n",
      "37/37 [==============================] - 9s 246ms/step - loss: 0.1695\n",
      "Epoch 50/200\n",
      "37/37 [==============================] - 10s 270ms/step - loss: 0.1656\n",
      "Epoch 51/200\n",
      "37/37 [==============================] - 10s 261ms/step - loss: 0.1647\n",
      "Epoch 52/200\n",
      "37/37 [==============================] - 9s 241ms/step - loss: 0.1626\n",
      "Epoch 53/200\n",
      "37/37 [==============================] - 10s 259ms/step - loss: 0.1611\n",
      "Epoch 54/200\n",
      "37/37 [==============================] - 10s 246ms/step - loss: 0.1590\n",
      "Epoch 55/200\n",
      "37/37 [==============================] - 11s 297ms/step - loss: 0.1573\n",
      "Epoch 56/200\n",
      "37/37 [==============================] - 11s 298ms/step - loss: 0.1568\n",
      "Epoch 57/200\n",
      "37/37 [==============================] - 11s 303ms/step - loss: 0.1532\n",
      "Epoch 58/200\n",
      "37/37 [==============================] - 12s 308ms/step - loss: 0.1509\n",
      "Epoch 59/200\n",
      "37/37 [==============================] - 11s 301ms/step - loss: 0.1506\n",
      "Epoch 60/200\n",
      "37/37 [==============================] - 11s 302ms/step - loss: 0.1490\n",
      "Epoch 61/200\n",
      "37/37 [==============================] - 11s 302ms/step - loss: 0.1483\n",
      "Epoch 62/200\n",
      "37/37 [==============================] - 11s 293ms/step - loss: 0.1476\n",
      "Epoch 63/200\n",
      "37/37 [==============================] - 12s 308ms/step - loss: 0.1460\n",
      "Epoch 64/200\n",
      "37/37 [==============================] - 11s 293ms/step - loss: 0.1451\n",
      "Epoch 65/200\n",
      "37/37 [==============================] - 11s 301ms/step - loss: 0.1454\n",
      "Epoch 66/200\n",
      "37/37 [==============================] - 11s 295ms/step - loss: 0.1416\n",
      "Epoch 67/200\n",
      "37/37 [==============================] - 11s 293ms/step - loss: 0.1405\n",
      "Epoch 68/200\n",
      "37/37 [==============================] - 11s 288ms/step - loss: 0.1404\n",
      "Epoch 69/200\n",
      "37/37 [==============================] - 11s 285ms/step - loss: 0.1391\n",
      "Epoch 70/200\n",
      "37/37 [==============================] - 10s 272ms/step - loss: 0.1388\n",
      "Epoch 71/200\n",
      "37/37 [==============================] - 10s 269ms/step - loss: 0.1379\n",
      "Epoch 72/200\n",
      "37/37 [==============================] - 11s 281ms/step - loss: 0.1367\n",
      "Epoch 73/200\n",
      "37/37 [==============================] - 10s 270ms/step - loss: 0.1343\n",
      "Epoch 74/200\n",
      "37/37 [==============================] - 10s 274ms/step - loss: 0.1348\n",
      "Epoch 75/200\n",
      "37/37 [==============================] - 10s 270ms/step - loss: 0.1340\n",
      "Epoch 76/200\n",
      "37/37 [==============================] - 11s 279ms/step - loss: 0.1329\n",
      "Epoch 77/200\n",
      "37/37 [==============================] - 11s 282ms/step - loss: 0.1325\n",
      "Epoch 78/200\n",
      "37/37 [==============================] - 10s 256ms/step - loss: 0.1320\n",
      "Epoch 79/200\n",
      "37/37 [==============================] - 10s 260ms/step - loss: 0.1307\n",
      "Epoch 80/200\n",
      "37/37 [==============================] - 10s 256ms/step - loss: 0.1312\n",
      "Epoch 81/200\n",
      "37/37 [==============================] - 9s 244ms/step - loss: 0.1319\n",
      "Epoch 82/200\n",
      "37/37 [==============================] - 9s 250ms/step - loss: 0.1301\n",
      "Epoch 83/200\n",
      "37/37 [==============================] - 9s 252ms/step - loss: 0.1291\n",
      "Epoch 84/200\n",
      "37/37 [==============================] - 10s 252ms/step - loss: 0.1277\n",
      "Epoch 85/200\n",
      "37/37 [==============================] - 10s 253ms/step - loss: 0.1273\n",
      "Epoch 86/200\n",
      "37/37 [==============================] - 9s 248ms/step - loss: 0.1253\n",
      "Epoch 87/200\n",
      "37/37 [==============================] - 9s 248ms/step - loss: 0.1266\n",
      "Epoch 88/200\n",
      "37/37 [==============================] - 10s 253ms/step - loss: 0.1245\n",
      "Epoch 89/200\n",
      "37/37 [==============================] - 10s 255ms/step - loss: 0.1250\n",
      "Epoch 90/200\n",
      "37/37 [==============================] - 9s 252ms/step - loss: 0.1249\n",
      "Epoch 91/200\n",
      "37/37 [==============================] - 10s 265ms/step - loss: 0.1252\n",
      "Epoch 92/200\n",
      "37/37 [==============================] - 10s 260ms/step - loss: 0.1234\n",
      "Epoch 93/200\n",
      "37/37 [==============================] - 10s 255ms/step - loss: 0.1229\n",
      "Epoch 94/200\n",
      "37/37 [==============================] - 9s 248ms/step - loss: 0.1221\n",
      "Epoch 95/200\n",
      "37/37 [==============================] - 9s 227ms/step - loss: 0.1228\n",
      "Epoch 96/200\n",
      "37/37 [==============================] - 9s 236ms/step - loss: 0.1248\n",
      "Epoch 97/200\n",
      "37/37 [==============================] - 9s 246ms/step - loss: 0.1224\n",
      "Epoch 98/200\n",
      "37/37 [==============================] - 9s 228ms/step - loss: 0.1217\n",
      "Epoch 99/200\n",
      "37/37 [==============================] - 9s 235ms/step - loss: 0.1207\n",
      "Epoch 100/200\n",
      "37/37 [==============================] - 9s 242ms/step - loss: 0.1205\n",
      "Epoch 101/200\n",
      "37/37 [==============================] - 9s 243ms/step - loss: 0.1190\n",
      "Epoch 102/200\n",
      "37/37 [==============================] - 8s 216ms/step - loss: 0.1212\n",
      "Epoch 103/200\n",
      "37/37 [==============================] - 7s 190ms/step - loss: 0.1223\n",
      "Epoch 104/200\n",
      "37/37 [==============================] - 7s 189ms/step - loss: 0.1218\n",
      "Epoch 105/200\n",
      "37/37 [==============================] - 7s 181ms/step - loss: 0.1184\n",
      "Epoch 106/200\n",
      "37/37 [==============================] - 8s 207ms/step - loss: 0.1187\n",
      "Epoch 107/200\n",
      "37/37 [==============================] - 9s 237ms/step - loss: 0.1219\n",
      "Epoch 108/200\n",
      "37/37 [==============================] - 10s 267ms/step - loss: 0.1189\n",
      "Epoch 109/200\n",
      "37/37 [==============================] - 10s 277ms/step - loss: 0.1188\n",
      "Epoch 110/200\n",
      "37/37 [==============================] - 10s 265ms/step - loss: 0.1177\n",
      "Epoch 111/200\n",
      "37/37 [==============================] - 10s 268ms/step - loss: 0.1173\n",
      "Epoch 112/200\n",
      "37/37 [==============================] - 10s 275ms/step - loss: 0.1151\n",
      "Epoch 113/200\n",
      "37/37 [==============================] - 10s 267ms/step - loss: 0.1154\n",
      "Epoch 114/200\n",
      "37/37 [==============================] - 10s 266ms/step - loss: 0.1146\n",
      "Epoch 115/200\n",
      "37/37 [==============================] - 10s 269ms/step - loss: 0.1147\n",
      "Epoch 116/200\n",
      "37/37 [==============================] - 9s 244ms/step - loss: 0.1134\n",
      "Epoch 117/200\n",
      "37/37 [==============================] - 10s 269ms/step - loss: 0.1126\n",
      "Epoch 118/200\n",
      "37/37 [==============================] - 10s 268ms/step - loss: 0.1133\n",
      "Epoch 119/200\n",
      "37/37 [==============================] - 10s 262ms/step - loss: 0.1154\n",
      "Epoch 120/200\n",
      "37/37 [==============================] - 10s 255ms/step - loss: 0.1138\n",
      "Epoch 121/200\n",
      "37/37 [==============================] - 10s 259ms/step - loss: 0.1154\n",
      "Epoch 122/200\n",
      "37/37 [==============================] - 10s 259ms/step - loss: 0.1146\n",
      "Epoch 123/200\n",
      "37/37 [==============================] - 10s 255ms/step - loss: 0.1148\n",
      "Epoch 124/200\n",
      "37/37 [==============================] - 9s 241ms/step - loss: 0.1148\n",
      "Epoch 125/200\n",
      "37/37 [==============================] - 9s 243ms/step - loss: 0.1153\n",
      "Epoch 126/200\n",
      "37/37 [==============================] - 9s 238ms/step - loss: 0.1143\n",
      "Epoch 127/200\n",
      "37/37 [==============================] - 9s 251ms/step - loss: 0.1146\n",
      "Epoch 128/200\n",
      "37/37 [==============================] - 9s 248ms/step - loss: 0.1142\n",
      "Epoch 129/200\n",
      "37/37 [==============================] - 9s 233ms/step - loss: 0.1146\n",
      "Epoch 130/200\n",
      "37/37 [==============================] - 9s 245ms/step - loss: 0.1141\n",
      "Epoch 131/200\n",
      "37/37 [==============================] - 9s 229ms/step - loss: 0.1136\n",
      "Epoch 132/200\n",
      "37/37 [==============================] - 8s 219ms/step - loss: 0.1146\n",
      "Epoch 133/200\n",
      "37/37 [==============================] - 9s 226ms/step - loss: 0.1147\n",
      "Epoch 134/200\n",
      "37/37 [==============================] - 9s 232ms/step - loss: 0.1137\n",
      "Epoch 135/200\n",
      "37/37 [==============================] - 9s 233ms/step - loss: 0.1122\n",
      "Epoch 136/200\n",
      "37/37 [==============================] - 9s 235ms/step - loss: 0.1112\n",
      "Epoch 137/200\n",
      "37/37 [==============================] - 9s 225ms/step - loss: 0.1095\n",
      "Epoch 138/200\n",
      "37/37 [==============================] - 9s 228ms/step - loss: 0.1093\n",
      "Epoch 139/200\n",
      "37/37 [==============================] - 9s 232ms/step - loss: 0.1080\n",
      "Epoch 140/200\n",
      "37/37 [==============================] - 9s 230ms/step - loss: 0.1073\n",
      "Epoch 141/200\n",
      "37/37 [==============================] - 9s 235ms/step - loss: 0.1067\n",
      "Epoch 142/200\n",
      "37/37 [==============================] - 9s 232ms/step - loss: 0.1061\n",
      "Epoch 143/200\n",
      "37/37 [==============================] - 8s 221ms/step - loss: 0.1071\n",
      "Epoch 144/200\n",
      "37/37 [==============================] - 9s 226ms/step - loss: 0.1070\n",
      "Epoch 145/200\n",
      "37/37 [==============================] - 9s 227ms/step - loss: 0.1062\n",
      "Epoch 146/200\n",
      "37/37 [==============================] - 9s 229ms/step - loss: 0.1076\n",
      "Epoch 147/200\n",
      "37/37 [==============================] - 9s 230ms/step - loss: 0.1076\n",
      "Epoch 148/200\n",
      "37/37 [==============================] - 9s 228ms/step - loss: 0.1075\n",
      "Epoch 149/200\n",
      "37/37 [==============================] - 8s 225ms/step - loss: 0.1097\n",
      "Epoch 150/200\n",
      "37/37 [==============================] - 8s 218ms/step - loss: 0.1106\n",
      "Epoch 151/200\n",
      "37/37 [==============================] - 9s 232ms/step - loss: 0.1109\n",
      "Epoch 152/200\n",
      "37/37 [==============================] - 9s 232ms/step - loss: 0.1112\n",
      "Epoch 153/200\n",
      "37/37 [==============================] - 9s 233ms/step - loss: 0.1130\n",
      "Epoch 154/200\n",
      "37/37 [==============================] - 9s 233ms/step - loss: 0.1149\n",
      "Epoch 155/200\n",
      "37/37 [==============================] - 9s 236ms/step - loss: 0.1170\n",
      "Epoch 156/200\n",
      "37/37 [==============================] - 9s 237ms/step - loss: 0.1214\n",
      "Epoch 157/200\n",
      "37/37 [==============================] - 9s 235ms/step - loss: 0.1219\n",
      "Epoch 158/200\n",
      "37/37 [==============================] - 9s 233ms/step - loss: 0.1276\n",
      "Epoch 159/200\n",
      "37/37 [==============================] - 9s 231ms/step - loss: 0.1276\n",
      "Epoch 160/200\n",
      "37/37 [==============================] - 9s 233ms/step - loss: 0.1306\n",
      "Epoch 161/200\n",
      "37/37 [==============================] - 9s 234ms/step - loss: 0.1295\n",
      "Epoch 162/200\n",
      "37/37 [==============================] - 9s 230ms/step - loss: 0.1278\n",
      "Epoch 163/200\n",
      "37/37 [==============================] - 9s 233ms/step - loss: 0.1236\n",
      "Epoch 164/200\n",
      "37/37 [==============================] - 8s 219ms/step - loss: 0.1177\n",
      "Epoch 165/200\n",
      "37/37 [==============================] - 9s 231ms/step - loss: 0.1135\n",
      "Epoch 166/200\n",
      "37/37 [==============================] - 9s 231ms/step - loss: 0.1092\n",
      "Epoch 167/200\n",
      "37/37 [==============================] - 9s 230ms/step - loss: 0.1076\n",
      "Epoch 168/200\n",
      "37/37 [==============================] - 9s 227ms/step - loss: 0.1048\n",
      "Epoch 169/200\n",
      "37/37 [==============================] - 9s 226ms/step - loss: 0.1029\n",
      "Epoch 170/200\n",
      "37/37 [==============================] - 9s 226ms/step - loss: 0.1008\n",
      "Epoch 171/200\n",
      "37/37 [==============================] - 9s 227ms/step - loss: 0.1002\n",
      "Epoch 172/200\n",
      "37/37 [==============================] - 9s 229ms/step - loss: 0.1005\n",
      "Epoch 173/200\n",
      "37/37 [==============================] - 9s 227ms/step - loss: 0.1002\n",
      "Epoch 174/200\n",
      "37/37 [==============================] - 9s 227ms/step - loss: 0.0972\n",
      "Epoch 175/200\n",
      "37/37 [==============================] - 9s 236ms/step - loss: 0.0965\n",
      "Epoch 176/200\n",
      "37/37 [==============================] - 9s 225ms/step - loss: 0.0983\n",
      "Epoch 177/200\n",
      "37/37 [==============================] - 9s 234ms/step - loss: 0.0984\n",
      "Epoch 178/200\n",
      "37/37 [==============================] - 9s 235ms/step - loss: 0.0965\n",
      "Epoch 179/200\n",
      "37/37 [==============================] - 9s 236ms/step - loss: 0.0967\n",
      "Epoch 180/200\n",
      "37/37 [==============================] - 9s 240ms/step - loss: 0.0978\n",
      "Epoch 181/200\n",
      "37/37 [==============================] - 9s 243ms/step - loss: 0.0978\n",
      "Epoch 182/200\n",
      "37/37 [==============================] - 9s 241ms/step - loss: 0.0999\n",
      "Epoch 183/200\n",
      "37/37 [==============================] - 9s 242ms/step - loss: 0.0990\n",
      "Epoch 184/200\n",
      "37/37 [==============================] - 9s 229ms/step - loss: 0.0986\n",
      "Epoch 185/200\n",
      "37/37 [==============================] - 9s 241ms/step - loss: 0.0993\n",
      "Epoch 186/200\n",
      "37/37 [==============================] - 9s 239ms/step - loss: 0.1006\n",
      "Epoch 187/200\n",
      "37/37 [==============================] - 9s 236ms/step - loss: 0.1014\n",
      "Epoch 188/200\n",
      "37/37 [==============================] - 9s 245ms/step - loss: 0.1023\n",
      "Epoch 189/200\n",
      "37/37 [==============================] - 9s 238ms/step - loss: 0.1041\n",
      "Epoch 190/200\n",
      "37/37 [==============================] - 9s 234ms/step - loss: 0.1046\n",
      "Epoch 191/200\n",
      "37/37 [==============================] - 9s 237ms/step - loss: 0.1133\n",
      "Epoch 192/200\n",
      "37/37 [==============================] - 9s 242ms/step - loss: 0.1248\n",
      "Epoch 193/200\n",
      "37/37 [==============================] - 8s 213ms/step - loss: 0.1606\n",
      "Epoch 194/200\n",
      "37/37 [==============================] - 9s 241ms/step - loss: 0.2539\n",
      "Epoch 195/200\n",
      "37/37 [==============================] - 9s 230ms/step - loss: 0.3329\n",
      "Epoch 196/200\n",
      "37/37 [==============================] - 9s 228ms/step - loss: 0.3234\n",
      "Epoch 197/200\n",
      "37/37 [==============================] - 8s 220ms/step - loss: 0.2823\n",
      "Epoch 198/200\n",
      "37/37 [==============================] - 9s 225ms/step - loss: 0.2443\n",
      "Epoch 199/200\n",
      "37/37 [==============================] - 9s 231ms/step - loss: 0.2080\n",
      "Epoch 200/200\n",
      "37/37 [==============================] - 9s 228ms/step - loss: 0.1776\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 200\n",
    "\n",
    "history = model.fit(dataset, epochs=EPOCHS)\n",
    "\n",
    "# Guardamos el modelo y los pesos\n",
    "model.save_weights('./modelos/sanchez_weights.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el modelo para generar texto de Pedro Sánchez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)\n",
    "\n",
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "model.load_weights('./modelos/sanchez_weights.keras')\n",
    "model.build(tf.TensorShape([1, None]))\n",
    "\n",
    "model.save('./modelos/sanchez.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos el texto generado por Pedro Sánchez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fíjense, señor Casado, que es la unidad del conjunto de las fuerzas de esta Cámara, sobre todo para poner en marcha —de corazón se la pasada más responsabilidad de Pala comunidad autónoma más afectada hasta ahora por la particas, al menos, señoría, yo tengo más claro que se haganes de euros. Es verdad que el tramo cuarto, que se refiere precisamente a le diré una cosa: ustedes han representado la continuidad y el cambio; la continuidad en las malas a través del esfuerzo de las ayudas de CO2, e\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, start_string=u\"Que opina del señor Abascal?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de Pablo Casado (GRU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el dataset de entrenamiento de Pablo Casado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abrir el texto\n",
    "text = open(datos_casado, 'rb').read().decode(encoding='utf-8')\n",
    "\n",
    "# Vectorizar el texto\n",
    "text_as_int = np.array([char2idx[c] for c in text])\n",
    "\n",
    "# Secuencias de 100 carácteres\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "SEQ_LENGTH = 100\n",
    "sequences = char_dataset.batch(SEQ_LENGTH + 1, drop_remainder=True)\n",
    "\n",
    "# Dataset de entrenamiento\n",
    "dataset = sequences.map(split_input_target)\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = (\n",
    "    dataset\n",
    "    .shuffle(BUFFER_SIZE)\n",
    "    .batch(BATCH_SIZE, drop_remainder=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el modelo de Pablo Casado, como lo haremos con GRU tendremos que hacer una nueva implementación de model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gru_model(tf.keras.Model):\n",
    "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "    super().__init__(self)\n",
    "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
    "                                   return_sequences=True,\n",
    "                                   return_state=True)\n",
    "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "  def call(self, inputs, states=None, return_state=False, training=False):\n",
    "    x = inputs\n",
    "    x = self.embedding(x, training=training)\n",
    "    if states is None:\n",
    "      states = self.gru.get_initial_state(x)\n",
    "    x, states = self.gru(x, initial_state=states, training=training)\n",
    "    x = self.dense(x, training=training)\n",
    "\n",
    "    if return_state:\n",
    "      return x, states\n",
    "    else:\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gru_model(\n",
    "    # Be sure the vocabulary size matches the `StringLookup` layers.\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)\n",
    "\n",
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo de Pablo Casado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "16/16 [==============================] - 8s 139ms/step - loss: 5.2356\n",
      "Epoch 2/200\n",
      "16/16 [==============================] - 2s 134ms/step - loss: 2.9608\n",
      "Epoch 3/200\n",
      "16/16 [==============================] - 2s 135ms/step - loss: 2.5745\n",
      "Epoch 4/200\n",
      "16/16 [==============================] - 2s 135ms/step - loss: 2.3653\n",
      "Epoch 5/200\n",
      "16/16 [==============================] - 2s 138ms/step - loss: 2.2457\n",
      "Epoch 6/200\n",
      "16/16 [==============================] - 2s 133ms/step - loss: 2.1553\n",
      "Epoch 7/200\n",
      "16/16 [==============================] - 2s 126ms/step - loss: 2.0795\n",
      "Epoch 8/200\n",
      "16/16 [==============================] - 2s 132ms/step - loss: 2.0068\n",
      "Epoch 9/200\n",
      "16/16 [==============================] - 2s 137ms/step - loss: 1.9351\n",
      "Epoch 10/200\n",
      "16/16 [==============================] - 2s 138ms/step - loss: 1.8646\n",
      "Epoch 11/200\n",
      "16/16 [==============================] - 2s 137ms/step - loss: 1.7938\n",
      "Epoch 12/200\n",
      "16/16 [==============================] - 2s 137ms/step - loss: 1.7229\n",
      "Epoch 13/200\n",
      "16/16 [==============================] - 2s 144ms/step - loss: 1.6542\n",
      "Epoch 14/200\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 1.5863\n",
      "Epoch 15/200\n",
      "16/16 [==============================] - 2s 147ms/step - loss: 1.5170\n",
      "Epoch 16/200\n",
      "16/16 [==============================] - 2s 140ms/step - loss: 1.4494\n",
      "Epoch 17/200\n",
      "16/16 [==============================] - 2s 134ms/step - loss: 1.3819\n",
      "Epoch 18/200\n",
      "16/16 [==============================] - 2s 138ms/step - loss: 1.3101\n",
      "Epoch 19/200\n",
      "16/16 [==============================] - 2s 135ms/step - loss: 1.2377\n",
      "Epoch 20/200\n",
      "16/16 [==============================] - 2s 136ms/step - loss: 1.1696\n",
      "Epoch 21/200\n",
      "16/16 [==============================] - 2s 134ms/step - loss: 1.0990\n",
      "Epoch 22/200\n",
      "16/16 [==============================] - 2s 136ms/step - loss: 1.0219\n",
      "Epoch 23/200\n",
      "16/16 [==============================] - 2s 138ms/step - loss: 0.9448\n",
      "Epoch 24/200\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.8638\n",
      "Epoch 25/200\n",
      "16/16 [==============================] - 2s 136ms/step - loss: 0.7828\n",
      "Epoch 26/200\n",
      "16/16 [==============================] - 2s 137ms/step - loss: 0.6992\n",
      "Epoch 27/200\n",
      "16/16 [==============================] - 2s 138ms/step - loss: 0.6177\n",
      "Epoch 28/200\n",
      "16/16 [==============================] - 2s 141ms/step - loss: 0.5348\n",
      "Epoch 29/200\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.4548\n",
      "Epoch 30/200\n",
      "16/16 [==============================] - 2s 141ms/step - loss: 0.3808\n",
      "Epoch 31/200\n",
      "16/16 [==============================] - 2s 148ms/step - loss: 0.3162\n",
      "Epoch 32/200\n",
      "16/16 [==============================] - 2s 145ms/step - loss: 0.2611\n",
      "Epoch 33/200\n",
      "16/16 [==============================] - 2s 145ms/step - loss: 0.2139\n",
      "Epoch 34/200\n",
      "16/16 [==============================] - 3s 152ms/step - loss: 0.1797\n",
      "Epoch 35/200\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 0.1527\n",
      "Epoch 36/200\n",
      "16/16 [==============================] - 2s 147ms/step - loss: 0.1320\n",
      "Epoch 37/200\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 0.1160\n",
      "Epoch 38/200\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 0.1043\n",
      "Epoch 39/200\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.0963\n",
      "Epoch 40/200\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 0.0907\n",
      "Epoch 41/200\n",
      "16/16 [==============================] - 2s 141ms/step - loss: 0.0846\n",
      "Epoch 42/200\n",
      "16/16 [==============================] - 2s 144ms/step - loss: 0.0798\n",
      "Epoch 43/200\n",
      "16/16 [==============================] - 2s 137ms/step - loss: 0.0757\n",
      "Epoch 44/200\n",
      "16/16 [==============================] - 2s 135ms/step - loss: 0.0723\n",
      "Epoch 45/200\n",
      "16/16 [==============================] - 2s 139ms/step - loss: 0.0687\n",
      "Epoch 46/200\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.0673\n",
      "Epoch 47/200\n",
      "16/16 [==============================] - 2s 147ms/step - loss: 0.0657\n",
      "Epoch 48/200\n",
      "16/16 [==============================] - 2s 150ms/step - loss: 0.0636\n",
      "Epoch 49/200\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 0.0619\n",
      "Epoch 50/200\n",
      "16/16 [==============================] - 2s 148ms/step - loss: 0.0606\n",
      "Epoch 51/200\n",
      "16/16 [==============================] - 2s 139ms/step - loss: 0.0604\n",
      "Epoch 52/200\n",
      "16/16 [==============================] - 2s 138ms/step - loss: 0.0593\n",
      "Epoch 53/200\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.0588\n",
      "Epoch 54/200\n",
      "16/16 [==============================] - 3s 154ms/step - loss: 0.0580\n",
      "Epoch 55/200\n",
      "16/16 [==============================] - 2s 150ms/step - loss: 0.0575\n",
      "Epoch 56/200\n",
      "16/16 [==============================] - 2s 145ms/step - loss: 0.0573\n",
      "Epoch 57/200\n",
      "16/16 [==============================] - 2s 149ms/step - loss: 0.0560\n",
      "Epoch 58/200\n",
      "16/16 [==============================] - 2s 149ms/step - loss: 0.0552\n",
      "Epoch 59/200\n",
      "16/16 [==============================] - 2s 149ms/step - loss: 0.0546\n",
      "Epoch 60/200\n",
      "16/16 [==============================] - 2s 150ms/step - loss: 0.0542\n",
      "Epoch 61/200\n",
      "16/16 [==============================] - 3s 151ms/step - loss: 0.0536\n",
      "Epoch 62/200\n",
      "16/16 [==============================] - 3s 152ms/step - loss: 0.0535\n",
      "Epoch 63/200\n",
      "16/16 [==============================] - 2s 145ms/step - loss: 0.0537\n",
      "Epoch 64/200\n",
      "16/16 [==============================] - 3s 156ms/step - loss: 0.0528\n",
      "Epoch 65/200\n",
      "16/16 [==============================] - 2s 147ms/step - loss: 0.0527\n",
      "Epoch 66/200\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 0.0521\n",
      "Epoch 67/200\n",
      "16/16 [==============================] - 2s 148ms/step - loss: 0.0517\n",
      "Epoch 68/200\n",
      "16/16 [==============================] - 3s 153ms/step - loss: 0.0516\n",
      "Epoch 69/200\n",
      "16/16 [==============================] - 3s 155ms/step - loss: 0.0517\n",
      "Epoch 70/200\n",
      "16/16 [==============================] - 3s 151ms/step - loss: 0.0527\n",
      "Epoch 71/200\n",
      "16/16 [==============================] - 3s 157ms/step - loss: 0.0547\n",
      "Epoch 72/200\n",
      "16/16 [==============================] - 3s 152ms/step - loss: 0.0546\n",
      "Epoch 73/200\n",
      "16/16 [==============================] - 3s 159ms/step - loss: 0.0569\n",
      "Epoch 74/200\n",
      "16/16 [==============================] - 3s 159ms/step - loss: 0.0601\n",
      "Epoch 75/200\n",
      "16/16 [==============================] - 3s 153ms/step - loss: 0.0650\n",
      "Epoch 76/200\n",
      "16/16 [==============================] - 3s 157ms/step - loss: 0.0703\n",
      "Epoch 77/200\n",
      "16/16 [==============================] - 3s 160ms/step - loss: 0.0777\n",
      "Epoch 78/200\n",
      "16/16 [==============================] - 2s 149ms/step - loss: 0.0849\n",
      "Epoch 79/200\n",
      "16/16 [==============================] - 3s 155ms/step - loss: 0.0817\n",
      "Epoch 80/200\n",
      "16/16 [==============================] - 2s 148ms/step - loss: 0.0784\n",
      "Epoch 81/200\n",
      "16/16 [==============================] - 2s 148ms/step - loss: 0.0728\n",
      "Epoch 82/200\n",
      "16/16 [==============================] - 3s 160ms/step - loss: 0.0668\n",
      "Epoch 83/200\n",
      "16/16 [==============================] - 2s 151ms/step - loss: 0.0612\n",
      "Epoch 84/200\n",
      "16/16 [==============================] - 3s 162ms/step - loss: 0.0562\n",
      "Epoch 85/200\n",
      "16/16 [==============================] - 3s 159ms/step - loss: 0.0525\n",
      "Epoch 86/200\n",
      "16/16 [==============================] - 2s 147ms/step - loss: 0.0507\n",
      "Epoch 87/200\n",
      "16/16 [==============================] - 3s 159ms/step - loss: 0.0498\n",
      "Epoch 88/200\n",
      "16/16 [==============================] - 3s 163ms/step - loss: 0.0495\n",
      "Epoch 89/200\n",
      "16/16 [==============================] - 3s 159ms/step - loss: 0.0494\n",
      "Epoch 90/200\n",
      "16/16 [==============================] - 3s 148ms/step - loss: 0.0486\n",
      "Epoch 91/200\n",
      "16/16 [==============================] - 2s 147ms/step - loss: 0.0482\n",
      "Epoch 92/200\n",
      "16/16 [==============================] - 2s 141ms/step - loss: 0.0479\n",
      "Epoch 93/200\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 0.0474\n",
      "Epoch 94/200\n",
      "16/16 [==============================] - 2s 113ms/step - loss: 0.0474\n",
      "Epoch 95/200\n",
      "16/16 [==============================] - 2s 103ms/step - loss: 0.0476\n",
      "Epoch 96/200\n",
      "16/16 [==============================] - 2s 147ms/step - loss: 0.0472\n",
      "Epoch 97/200\n",
      "16/16 [==============================] - 2s 143ms/step - loss: 0.0471\n",
      "Epoch 98/200\n",
      "16/16 [==============================] - 3s 154ms/step - loss: 0.0471\n",
      "Epoch 99/200\n",
      "16/16 [==============================] - 3s 161ms/step - loss: 0.0467\n",
      "Epoch 100/200\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 0.0470\n",
      "Epoch 101/200\n",
      "16/16 [==============================] - 2s 151ms/step - loss: 0.0470\n",
      "Epoch 102/200\n",
      "16/16 [==============================] - 2s 145ms/step - loss: 0.0467\n",
      "Epoch 103/200\n",
      "16/16 [==============================] - 2s 151ms/step - loss: 0.0467\n",
      "Epoch 104/200\n",
      "16/16 [==============================] - 2s 146ms/step - loss: 0.0463\n",
      "Epoch 105/200\n",
      "16/16 [==============================] - 2s 150ms/step - loss: 0.0467\n",
      "Epoch 106/200\n",
      "16/16 [==============================] - 2s 149ms/step - loss: 0.0465\n",
      "Epoch 107/200\n",
      "16/16 [==============================] - 3s 153ms/step - loss: 0.0467\n",
      "Epoch 108/200\n",
      "16/16 [==============================] - 3s 166ms/step - loss: 0.0467\n",
      "Epoch 109/200\n",
      "16/16 [==============================] - 3s 154ms/step - loss: 0.0466\n",
      "Epoch 110/200\n",
      "16/16 [==============================] - 3s 155ms/step - loss: 0.0463\n",
      "Epoch 111/200\n",
      "16/16 [==============================] - 3s 151ms/step - loss: 0.0464\n",
      "Epoch 112/200\n",
      "16/16 [==============================] - 2s 142ms/step - loss: 0.0463\n",
      "Epoch 113/200\n",
      "16/16 [==============================] - 2s 144ms/step - loss: 0.0463\n",
      "Epoch 114/200\n",
      "16/16 [==============================] - 2s 140ms/step - loss: 0.0462\n",
      "Epoch 115/200\n",
      "16/16 [==============================] - 3s 159ms/step - loss: 0.0462\n",
      "Epoch 116/200\n",
      "16/16 [==============================] - 3s 154ms/step - loss: 0.0468\n",
      "Epoch 117/200\n",
      "16/16 [==============================] - 3s 152ms/step - loss: 0.0464\n",
      "Epoch 118/200\n",
      "16/16 [==============================] - 3s 155ms/step - loss: 0.0462\n",
      "Epoch 119/200\n",
      "16/16 [==============================] - 2s 138ms/step - loss: 0.0465\n",
      "Epoch 120/200\n",
      "16/16 [==============================] - 3s 174ms/step - loss: 0.0468\n",
      "Epoch 121/200\n",
      "16/16 [==============================] - 3s 182ms/step - loss: 0.0478\n",
      "Epoch 122/200\n",
      "16/16 [==============================] - 3s 175ms/step - loss: 0.0490\n",
      "Epoch 123/200\n",
      "16/16 [==============================] - 3s 195ms/step - loss: 0.0485\n",
      "Epoch 124/200\n",
      "16/16 [==============================] - 3s 187ms/step - loss: 0.0489\n",
      "Epoch 125/200\n",
      "16/16 [==============================] - 3s 179ms/step - loss: 0.0489\n",
      "Epoch 126/200\n",
      "16/16 [==============================] - 3s 188ms/step - loss: 0.0509\n",
      "Epoch 127/200\n",
      "16/16 [==============================] - 3s 190ms/step - loss: 0.0507\n",
      "Epoch 128/200\n",
      "16/16 [==============================] - 3s 188ms/step - loss: 0.0517\n",
      "Epoch 129/200\n",
      "16/16 [==============================] - 3s 183ms/step - loss: 0.0518\n",
      "Epoch 130/200\n",
      "16/16 [==============================] - 3s 176ms/step - loss: 0.0525\n",
      "Epoch 131/200\n",
      "16/16 [==============================] - 3s 178ms/step - loss: 0.0533\n",
      "Epoch 132/200\n",
      "16/16 [==============================] - 3s 164ms/step - loss: 0.0544\n",
      "Epoch 133/200\n",
      "16/16 [==============================] - 3s 182ms/step - loss: 0.0558\n",
      "Epoch 134/200\n",
      "16/16 [==============================] - 3s 162ms/step - loss: 0.0590\n",
      "Epoch 135/200\n",
      "16/16 [==============================] - 3s 158ms/step - loss: 0.0618\n",
      "Epoch 136/200\n",
      "16/16 [==============================] - 3s 160ms/step - loss: 0.0657\n",
      "Epoch 137/200\n",
      "16/16 [==============================] - 3s 157ms/step - loss: 0.0692\n",
      "Epoch 138/200\n",
      "16/16 [==============================] - 3s 156ms/step - loss: 0.0730\n",
      "Epoch 139/200\n",
      "16/16 [==============================] - 3s 155ms/step - loss: 0.0763\n",
      "Epoch 140/200\n",
      "16/16 [==============================] - 3s 155ms/step - loss: 0.0794\n",
      "Epoch 141/200\n",
      "16/16 [==============================] - 3s 153ms/step - loss: 0.0811\n",
      "Epoch 142/200\n",
      "16/16 [==============================] - 3s 159ms/step - loss: 0.0804\n",
      "Epoch 143/200\n",
      "16/16 [==============================] - 3s 160ms/step - loss: 0.0777\n",
      "Epoch 144/200\n",
      "16/16 [==============================] - 3s 166ms/step - loss: 0.0729\n",
      "Epoch 145/200\n",
      "16/16 [==============================] - 3s 165ms/step - loss: 0.0665\n",
      "Epoch 146/200\n",
      "16/16 [==============================] - 3s 152ms/step - loss: 0.0612\n",
      "Epoch 147/200\n",
      "16/16 [==============================] - 3s 154ms/step - loss: 0.0566\n",
      "Epoch 148/200\n",
      "16/16 [==============================] - 3s 159ms/step - loss: 0.0532\n",
      "Epoch 149/200\n",
      "16/16 [==============================] - 3s 158ms/step - loss: 0.0513\n",
      "Epoch 150/200\n",
      "16/16 [==============================] - 3s 161ms/step - loss: 0.0494\n",
      "Epoch 151/200\n",
      "16/16 [==============================] - 3s 157ms/step - loss: 0.0488\n",
      "Epoch 152/200\n",
      "16/16 [==============================] - 3s 159ms/step - loss: 0.0479\n",
      "Epoch 153/200\n",
      "16/16 [==============================] - 3s 170ms/step - loss: 0.0470\n",
      "Epoch 154/200\n",
      "16/16 [==============================] - 3s 157ms/step - loss: 0.0468\n",
      "Epoch 155/200\n",
      "16/16 [==============================] - 3s 166ms/step - loss: 0.0466\n",
      "Epoch 156/200\n",
      "16/16 [==============================] - 3s 159ms/step - loss: 0.0466\n",
      "Epoch 157/200\n",
      "16/16 [==============================] - 3s 160ms/step - loss: 0.0463\n",
      "Epoch 158/200\n",
      "16/16 [==============================] - 3s 162ms/step - loss: 0.0464\n",
      "Epoch 159/200\n",
      "16/16 [==============================] - 3s 167ms/step - loss: 0.0464\n",
      "Epoch 160/200\n",
      "16/16 [==============================] - 3s 168ms/step - loss: 0.0461\n",
      "Epoch 161/200\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 0.0465\n",
      "Epoch 162/200\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.0467\n",
      "Epoch 163/200\n",
      "16/16 [==============================] - 3s 183ms/step - loss: 0.0467\n",
      "Epoch 164/200\n",
      "16/16 [==============================] - 3s 191ms/step - loss: 0.0462\n",
      "Epoch 165/200\n",
      "16/16 [==============================] - 3s 179ms/step - loss: 0.0465\n",
      "Epoch 166/200\n",
      "16/16 [==============================] - 3s 178ms/step - loss: 0.0458\n",
      "Epoch 167/200\n",
      "16/16 [==============================] - 3s 184ms/step - loss: 0.0459\n",
      "Epoch 168/200\n",
      "16/16 [==============================] - 3s 184ms/step - loss: 0.0457\n",
      "Epoch 169/200\n",
      "16/16 [==============================] - 3s 171ms/step - loss: 0.0461\n",
      "Epoch 170/200\n",
      "16/16 [==============================] - 3s 176ms/step - loss: 0.0458\n",
      "Epoch 171/200\n",
      "16/16 [==============================] - 3s 184ms/step - loss: 0.0458\n",
      "Epoch 172/200\n",
      "16/16 [==============================] - 3s 186ms/step - loss: 0.0458\n",
      "Epoch 173/200\n",
      "16/16 [==============================] - 3s 180ms/step - loss: 0.0456\n",
      "Epoch 174/200\n",
      "16/16 [==============================] - 3s 178ms/step - loss: 0.0459\n",
      "Epoch 175/200\n",
      "16/16 [==============================] - 3s 184ms/step - loss: 0.0462\n",
      "Epoch 176/200\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 0.0455\n",
      "Epoch 177/200\n",
      "16/16 [==============================] - 3s 192ms/step - loss: 0.0454\n",
      "Epoch 178/200\n",
      "16/16 [==============================] - 3s 180ms/step - loss: 0.0456\n",
      "Epoch 179/200\n",
      "16/16 [==============================] - 3s 176ms/step - loss: 0.0457\n",
      "Epoch 180/200\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 0.0457\n",
      "Epoch 181/200\n",
      "16/16 [==============================] - 3s 164ms/step - loss: 0.0459\n",
      "Epoch 182/200\n",
      "16/16 [==============================] - 2s 132ms/step - loss: 0.0462\n",
      "Epoch 183/200\n",
      "16/16 [==============================] - 3s 157ms/step - loss: 0.0461\n",
      "Epoch 184/200\n",
      "16/16 [==============================] - 3s 161ms/step - loss: 0.0461\n",
      "Epoch 185/200\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 0.0459\n",
      "Epoch 186/200\n",
      "16/16 [==============================] - 3s 176ms/step - loss: 0.0458\n",
      "Epoch 187/200\n",
      "16/16 [==============================] - 2s 141ms/step - loss: 0.0455\n",
      "Epoch 188/200\n",
      "16/16 [==============================] - 2s 135ms/step - loss: 0.0455\n",
      "Epoch 189/200\n",
      "16/16 [==============================] - 3s 158ms/step - loss: 0.0454\n",
      "Epoch 190/200\n",
      "16/16 [==============================] - 3s 164ms/step - loss: 0.0453\n",
      "Epoch 191/200\n",
      "16/16 [==============================] - 3s 154ms/step - loss: 0.0454\n",
      "Epoch 192/200\n",
      "16/16 [==============================] - 3s 173ms/step - loss: 0.0454\n",
      "Epoch 193/200\n",
      "16/16 [==============================] - 3s 177ms/step - loss: 0.0450\n",
      "Epoch 194/200\n",
      "16/16 [==============================] - 3s 184ms/step - loss: 0.0451\n",
      "Epoch 195/200\n",
      "16/16 [==============================] - 3s 182ms/step - loss: 0.0453\n",
      "Epoch 196/200\n",
      "16/16 [==============================] - 3s 180ms/step - loss: 0.0453\n",
      "Epoch 197/200\n",
      "16/16 [==============================] - 3s 160ms/step - loss: 0.0457\n",
      "Epoch 198/200\n",
      "16/16 [==============================] - 3s 168ms/step - loss: 0.0451\n",
      "Epoch 199/200\n",
      "16/16 [==============================] - 3s 170ms/step - loss: 0.0457\n",
      "Epoch 200/200\n",
      "16/16 [==============================] - 3s 172ms/step - loss: 0.0452\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 200\n",
    "\n",
    "history = model.fit(dataset, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder generar texto con el nuevo modelo de GRU tendremos que crear una clase nueva de OneStep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneStep(tf.keras.Model):\n",
    "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
    "    super().__init__()\n",
    "    self.temperature = temperature\n",
    "    self.model = model\n",
    "    self.chars_from_ids = chars_from_ids\n",
    "    self.ids_from_chars = ids_from_chars\n",
    "\n",
    "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
    "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
    "    sparse_mask = tf.SparseTensor(\n",
    "        # Put a -inf at each bad index.\n",
    "        values=[-float('inf')]*len(skip_ids),\n",
    "        indices=skip_ids,\n",
    "        # Match the shape to the vocabulary\n",
    "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
    "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "  @tf.function\n",
    "  def generate_one_step(self, inputs, states=None):\n",
    "    # Convert strings to token IDs.\n",
    "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
    "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "\n",
    "    # Run the model.\n",
    "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
    "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
    "                                          return_state=True)\n",
    "    # Only use the last prediction.\n",
    "    predicted_logits = predicted_logits[:, -1, :]\n",
    "    predicted_logits = predicted_logits/self.temperature\n",
    "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
    "    predicted_logits = predicted_logits + self.prediction_mask\n",
    "\n",
    "    # Sample the output logits to generate token IDs.\n",
    "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "\n",
    "    # Convert from token ids to characters\n",
    "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "\n",
    "    # Return the characters and model state.\n",
    "    return predicted_chars, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    }
   ],
   "source": [
    "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)\n",
    "\n",
    "one_step_model.save('./modelos/casado.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobamos el texto generado por Pablo Casado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/tmp/ipykernel_83518/1970756946.py\", line 33, in generate_one_step  *\n        predicted_logits = predicted_logits + self.prediction_mask\n\n    ValueError: Dimensions must be equal, but are 108 and 109 for '{{node add}} = AddV2[T=DT_FLOAT](truediv, add/y)' with input shapes: [1,108], [109].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m result \u001b[38;5;241m=\u001b[39m [next_char]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m):\n\u001b[0;32m----> 7\u001b[0m   next_char, states \u001b[38;5;241m=\u001b[39m \u001b[43mone_step_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_one_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_char\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m   result\u001b[38;5;241m.\u001b[39mappend(next_char)\n\u001b[1;32m     10\u001b[0m result \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mstrings\u001b[38;5;241m.\u001b[39mjoin(result)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filegjtxv124.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__generate_one_step\u001b[0;34m(self, inputs, states)\u001b[0m\n\u001b[1;32m     13\u001b[0m predicted_logits \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(predicted_logits)[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n\u001b[1;32m     14\u001b[0m predicted_logits \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(predicted_logits) \u001b[38;5;241m/\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mtemperature\n\u001b[0;32m---> 15\u001b[0m predicted_logits \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredicted_logits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_mask\u001b[49m\n\u001b[1;32m     16\u001b[0m predicted_ids \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mcategorical, (ag__\u001b[38;5;241m.\u001b[39mld(predicted_logits),), \u001b[38;5;28mdict\u001b[39m(num_samples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), fscope)\n\u001b[1;32m     17\u001b[0m predicted_ids \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tf)\u001b[38;5;241m.\u001b[39msqueeze, (ag__\u001b[38;5;241m.\u001b[39mld(predicted_ids),), \u001b[38;5;28mdict\u001b[39m(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), fscope)\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/tmp/ipykernel_83518/1970756946.py\", line 33, in generate_one_step  *\n        predicted_logits = predicted_logits + self.prediction_mask\n\n    ValueError: Dimensions must be equal, but are 108 and 109 for '{{node add}} = AddV2[T=DT_FLOAT](truediv, add/y)' with input shapes: [1,108], [109].\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant(['CASADO:'])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "  result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
    "print('\\nRun time:', end - start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversación entre Pedro Sánchez, Pablo Casado y Santiago Abascal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero vamos a tener que diferenciar las tablas de traducción de cada uno de los modelos, ya que cada uno tiene su propio vocabulario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abascal:  Por eso tenga cuidado porque también ha perdido la de la luz. Oiga, por cierto, si usted pedía dimisiones cuando la luz subía un 8 %, ¿por qué no dimo dictaron la presidenta de la Comisión y el presidente del Consejo Europeo, el comisario europeo de la señora Calvo, a la señora Montero y al señor Planas. Usted tiene un secretario de Estado de Turiste esta gestión, y para coordinar bien las ayudas sociales, las medidas como la renta mínima, que sí le tenga que pagar un 30 % de luz? ¿No va a demo\n",
      "Sanchez: cracia española, que estamos sufriendo una oposición que no es solo después de sus palabras están sus aciendo con el Gobierno.  Si usted quiere llegar a acuerdos empecemos por lo básico, por lo que entiendo que se destruyan empleos y también empresas. Pero, fíjese, señor Casado, gracias a las medidas que nos trajo protección gracias al descubrimiento de la valunta. Este es un año, después de siempre los ciudadanos, ni de la protección y clasificación, los órganos y las autoridades que permiendo \n",
      "Casado: en Europa. En Europa gobernamos nosotros con ustedes, con un socialismo mucho más moderado y sin los ed dar un golpe al Estado es concordia, romper la igualdad de los españoles es convivencia y romper la igualdad de los españoles es convivencia y romper lo por sus competencias sino también por sus apellidos; hasta se lleva al de Sanidad, para negociar con los verdugos? Nosotros estamos con las víctimas, ¿y usted? .\n",
      "Mire, señor Sánchez, ¡si hasta The Estado sin acuerdo por primera vez en la histo\n",
      "Abascal: ria e intentó hacer lo mismo a dedo con el Consejo Ge rectificar, y si lo hace tendrá nuestra mano tendida. Es la única que puede evitar que usted caiga aquí ya para los ERTE, derogar la Ley de Seguridad Ciudadana que ha usado para expulsar a miles de inmigran que le hemos ofrecido desde hace meses. Retire ya el estado de alarma, señor Sánchez, porque, sinceramente, no me mira nunca y me da exactamente igual, pero apor hasta que ayer han imputado al fundador de su partido por financiación irregu\n",
      "Sanchez: ltimas de salud pública― sean dirimidas en esa comisión de evaluación erales, y la mejor de las reformas laborales, señoría, efectivamente, han realizado su cálculo y el Gobierno de España también de una pandemia inédita en la historia de la humanidad de la serio de Salud en la población y la prevención de trastornos mentales; la prevención, detección política». Es decir, la participación política, entendida el menos como la entiende la mayor para tener un espejo muy encuando precisamente cuál p\n",
      "Casado: or sus competencias sino también por sus apellidos; hasta se lleva al de Sanidad, para negociar con los verdugos? Nosotros estamos con las víctimas, ¿y usted? .\n",
      "Mire, señor Sánchez, ¡si hasta The Estado sin acuerdo por primera vez en la historia e intentó hacer lo mismo a dedo con el Consejo Gobierno.\n",
      "Acabo ya, señora presidenta. Nosotros sí le hemos ofrecido un plan de choque. Sí, y, además, hace para satisfacción de los que en estos cuarenta años no han aportado nada, no han sumado nada, no ha\n",
      "Abascal: n sumbién la propiedad privada como tercer principio, lo que hace que nadie entienda que usted defienda lo que as y de carantoñas a quien incumple la ley y sigue humillando a los catalanes constitucionalistas, que es la libertad de movimientos en apenas dos meses. A nivel internacional el reglamento sanitario internaturas suspensas. Tres, en la vertebración, ustedes acaban con la lengua vehicular, que es el castel PIB o no pueden paliar los 300 000 millones de euros que tiene el BCE de deuda sob\n",
      "Sanchez: re el PIB equivalente al descenso de recaudación previsto por las diputaciones forales en los territorios de nuestro país.  En segundo lugar, señoría, siempre pasa algo con la izquierda sobre el PIB equivalente al descensor de la bronca o el de la unidad. Si toma el de la unidad, aquí está el Gobierno; si usted quiere la bronca, ahí tiene a la ultraderecha.\n",
      "Muchas gracias, señora presidenta. Señor Casado, ¿la de las propuestas que ahora mismo está encima de la mesa por parte de algunos de esos G\n",
      "Casado: obiernos y lideran las grandes naciones. Esa es la España en la que creo, esa es la España que las cuatro asociaciones judiciales tengan que ir a Europa a denunciar que usted impide que en España son huérfanos a tres niños de cuatro, seis y ocho años. Los tuvo que cuidar su tía Teresa, que está aque las cuatro asociaciones judiciales tengan que ir a Europa a denunciar que usted impide que en España porque su empecinamiento cuesta vidas. .\n",
      "Si viviera en Ceuta o en Melilla me quedaría muy preocupa\n",
      "Abascal:  hace setenta y cinco años fue para contener el comunismo, no para patrocinarlo, como pedía el otro día su partido en 1982, que señala que en ese caso de epidemia se podrán cerrar locales. Para paliar los estragos de la crisis proponemos pagar de inmediato los ERTE pendientes y amplieren acabar con España y eso es ya todo lo que es usted. El pago que le piden por haberle metido en la institucionalidad, pero lo ha dicho exactamente: No se preocupe que no cambio de socios, y tenía que haber escuch\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "\n",
    "modelo_abascal = tf.keras.models.load_model('./modelos/abascal.keras')\n",
    "modelo_sanchez = tf.keras.models.load_model('./modelos/sanchez.keras')\n",
    "modelo_casado = tf.keras.models.load_model('./modelos/casado.keras')\n",
    "\n",
    "modelos = [modelo_abascal, modelo_sanchez, modelo_casado]\n",
    "politicos = [\"Abascal\", \"Sanchez\", \"Casado\"]\n",
    "\n",
    "ultima_palabra = u\"¿Que opina del señor Abascal?\"\n",
    "turno = random.randint(0,2)\n",
    "\n",
    "for i in range(10):\n",
    "    turno = (turno + 1) % 3\n",
    "    ultima_palabra = generate_text(modelos[turno], start_string=ultima_palabra)\n",
    "    print(f\"{politicos[turno]}: {ultima_palabra}\")\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "text_generation.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d53d9c447d15846ca7228ba81a89f63b35afa7d922a1ed0608df97a83621769d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
